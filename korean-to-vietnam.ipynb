{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2c4898",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:20.336027Z",
     "iopub.status.busy": "2022-05-15T07:31:20.335446Z",
     "iopub.status.idle": "2022-05-15T07:31:26.278235Z",
     "shell.execute_reply": "2022-05-15T07:31:26.277385Z"
    },
    "papermill": {
     "duration": 5.977882,
     "end_time": "2022-05-15T07:31:26.280783",
     "exception": false,
     "start_time": "2022-05-15T07:31:20.302901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense,Input, Embedding\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537bbefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:26.339230Z",
     "iopub.status.busy": "2022-05-15T07:31:26.339024Z",
     "iopub.status.idle": "2022-05-15T07:31:26.942256Z",
     "shell.execute_reply": "2022-05-15T07:31:26.941526Z"
    },
    "papermill": {
     "duration": 0.63428,
     "end_time": "2022-05-15T07:31:26.944132",
     "exception": false,
     "start_time": "2022-05-15T07:31:26.309852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kr</th>\n",
       "      <th>vn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요</td>\n",
       "      <td>tối nào tôi cũng đến gác mái để gặp bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요</td>\n",
       "      <td>tôi không hiểu câu này của thầy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요</td>\n",
       "      <td>thời gian trôi qua quá nhanh khi tôi bắt đầu s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요</td>\n",
       "      <td>nửa đêm hôm nay tôi sẽ trở về hàn quốc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지금 잠을 자면 깨어나지 못할 거 같아서 지금 가요</td>\n",
       "      <td>bây giờ mà ngủ chắc không thức dậy nổi đâu nên...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             kr  \\\n",
       "0     나는 매일 저녁 배트를 만나러 다락방으로 가요   \n",
       "1             선생님 이문장이 이해가 안 가요   \n",
       "2       컴퓨터를 시작하면 시간이 너무 빠르게 가요   \n",
       "3          나는 오늘 자정에 한국으로 돌아 가요   \n",
       "4  지금 잠을 자면 깨어나지 못할 거 같아서 지금 가요   \n",
       "\n",
       "                                                  vn  \n",
       "0            tối nào tôi cũng đến gác mái để gặp bat  \n",
       "1                    tôi không hiểu câu này của thầy  \n",
       "2  thời gian trôi qua quá nhanh khi tôi bắt đầu s...  \n",
       "3             nửa đêm hôm nay tôi sẽ trở về hàn quốc  \n",
       "4  bây giờ mà ngủ chắc không thức dậy nổi đâu nên...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../input/112k-korean-to-vietnamese-dataset/kr-vn-112k.csv',encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cb9418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.005746Z",
     "iopub.status.busy": "2022-05-15T07:31:27.005503Z",
     "iopub.status.idle": "2022-05-15T07:31:27.010221Z",
     "shell.execute_reply": "2022-05-15T07:31:27.009537Z"
    },
    "papermill": {
     "duration": 0.037282,
     "end_time": "2022-05-15T07:31:27.012904",
     "exception": false,
     "start_time": "2022-05-15T07:31:26.975622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data:  112856\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data: \",data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fb4991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.071714Z",
     "iopub.status.busy": "2022-05-15T07:31:27.071148Z",
     "iopub.status.idle": "2022-05-15T07:31:27.101089Z",
     "shell.execute_reply": "2022-05-15T07:31:27.100428Z"
    },
    "papermill": {
     "duration": 0.06115,
     "end_time": "2022-05-15T07:31:27.102752",
     "exception": false,
     "start_time": "2022-05-15T07:31:27.041602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kr    0\n",
       "vn    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33419a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.163224Z",
     "iopub.status.busy": "2022-05-15T07:31:27.162955Z",
     "iopub.status.idle": "2022-05-15T07:31:27.421307Z",
     "shell.execute_reply": "2022-05-15T07:31:27.420575Z"
    },
    "papermill": {
     "duration": 0.291795,
     "end_time": "2022-05-15T07:31:27.423986",
     "exception": false,
     "start_time": "2022-05-15T07:31:27.132191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows are:  13186\n"
     ]
    }
   ],
   "source": [
    "# checking duplicated data\n",
    "isDuplicated = data.duplicated().any()\n",
    "if isDuplicated:\n",
    "    total_duplicates = data.duplicated().sum()\n",
    "    print(\"Total duplicate rows are: \",total_duplicates)\n",
    "    data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fce273b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.485872Z",
     "iopub.status.busy": "2022-05-15T07:31:27.485253Z",
     "iopub.status.idle": "2022-05-15T07:31:27.503921Z",
     "shell.execute_reply": "2022-05-15T07:31:27.503117Z"
    },
    "papermill": {
     "duration": 0.050855,
     "end_time": "2022-05-15T07:31:27.505647",
     "exception": false,
     "start_time": "2022-05-15T07:31:27.454792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sampling 90000 rows randomly\n",
    "data = data.sample(n = 90000, random_state = 31)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1290369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.566784Z",
     "iopub.status.busy": "2022-05-15T07:31:27.566237Z",
     "iopub.status.idle": "2022-05-15T07:31:27.916911Z",
     "shell.execute_reply": "2022-05-15T07:31:27.915997Z"
    },
    "papermill": {
     "duration": 0.383668,
     "end_time": "2022-05-15T07:31:27.919104",
     "exception": false,
     "start_time": "2022-05-15T07:31:27.535436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## changing uppercase to lowercase\n",
    "data['kr'] = data['kr'].apply(lambda x: x.lower())\n",
    "data['vn']=data['vn'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "data['kr']=data['kr'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "data['vn']=data['vn'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82ea0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:27.980202Z",
     "iopub.status.busy": "2022-05-15T07:31:27.979530Z",
     "iopub.status.idle": "2022-05-15T07:31:28.994625Z",
     "shell.execute_reply": "2022-05-15T07:31:28.993849Z"
    },
    "papermill": {
     "duration": 1.047592,
     "end_time": "2022-05-15T07:31:28.996767",
     "exception": false,
     "start_time": "2022-05-15T07:31:27.949175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuations to exclude::  {'}', '(', '@', '-', '&', '<', '=', '/', '+', ']', '\"', '#', '$', '[', ')', ',', '{', '^', '\\\\', '`', '%', ';', '_', '.', '?', '>', '~', '*', '!', ':', '|', \"'\"}\n"
     ]
    }
   ],
   "source": [
    "to_exclude = set(string.punctuation) # Set of all special characters\n",
    "print(\"punctuations to exclude:: \",to_exclude)\n",
    "# Remove all the special characters\n",
    "data['kr']=data['kr'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))\n",
    "data['vn']=data['vn'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3d1dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:29.059706Z",
     "iopub.status.busy": "2022-05-15T07:31:29.059470Z",
     "iopub.status.idle": "2022-05-15T07:31:30.836489Z",
     "shell.execute_reply": "2022-05-15T07:31:30.835740Z"
    },
    "papermill": {
     "duration": 1.811456,
     "end_time": "2022-05-15T07:31:30.838967",
     "exception": false,
     "start_time": "2022-05-15T07:31:29.027511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import digits\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "data['kr']=data['kr'].apply(lambda x: x.translate(remove_digits))\n",
    "data['vn']=data['vn'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "data['kr'] = data['kr'].apply(lambda x: re.sub(\"[영일이삼사오육칠팔구십]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "data['kr']=data['kr'].apply(lambda x: x.strip())\n",
    "data['vn']=data['vn'].apply(lambda x: x.strip())\n",
    "data['kr']=data['kr'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "data['vn']=data['vn'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375d3b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:30.902786Z",
     "iopub.status.busy": "2022-05-15T07:31:30.902535Z",
     "iopub.status.idle": "2022-05-15T07:31:30.954359Z",
     "shell.execute_reply": "2022-05-15T07:31:30.953638Z"
    },
    "papermill": {
     "duration": 0.085228,
     "end_time": "2022-05-15T07:31:30.956266",
     "exception": false,
     "start_time": "2022-05-15T07:31:30.871038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## adding start and end token to the target sentence\n",
    "data['vn'] = data['vn'].apply(lambda x: \"START_ \" + x + \" _END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa08de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:31.018008Z",
     "iopub.status.busy": "2022-05-15T07:31:31.017681Z",
     "iopub.status.idle": "2022-05-15T07:31:31.243451Z",
     "shell.execute_reply": "2022-05-15T07:31:31.242752Z"
    },
    "papermill": {
     "duration": 0.258745,
     "end_time": "2022-05-15T07:31:31.245223",
     "exception": false,
     "start_time": "2022-05-15T07:31:30.986478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kr</th>\n",
       "      <th>vn</th>\n",
       "      <th>kr_length</th>\n",
       "      <th>vn_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59284</th>\n",
       "      <td>결과는 우리가 해결해야 할 두 가지를 알려주고 있어요</td>\n",
       "      <td>START_ kết quả này cho thấy hai điều chúng ta ...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16694</th>\n",
       "      <td>세탁기를 다시 쓸 수 있으면 좋을 거에요</td>\n",
       "      <td>START_ giá mà có thể sử dụng lại máy giặt thì ...</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73677</th>\n",
       "      <td>무용품나 가 중 가장 먼저 바꿔야 할 것은 뭐라고 생각하나요</td>\n",
       "      <td>START_ bạn nghĩ cái nào là vật dụng văn phòng ...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70879</th>\n",
       "      <td>그녀가 진을 보고 힘 난다고 했어요</td>\n",
       "      <td>START_ cô ấy nói rằng cô ấy nhìn thấy bức ảnh ...</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77177</th>\n",
       "      <td>아쉽군요 줄다리기가 상금 제 많은 종목인데</td>\n",
       "      <td>START_ tiếc thật kéo co là hạng mục có nhiều t...</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      kr  \\\n",
       "59284      결과는 우리가 해결해야 할 두 가지를 알려주고 있어요   \n",
       "16694             세탁기를 다시 쓸 수 있으면 좋을 거에요   \n",
       "73677  무용품나 가 중 가장 먼저 바꿔야 할 것은 뭐라고 생각하나요   \n",
       "70879                그녀가 진을 보고 힘 난다고 했어요   \n",
       "77177            아쉽군요 줄다리기가 상금 제 많은 종목인데   \n",
       "\n",
       "                                                      vn  kr_length  vn_length  \n",
       "59284  START_ kết quả này cho thấy hai điều chúng ta ...          8         14  \n",
       "16694  START_ giá mà có thể sử dụng lại máy giặt thì ...          7         15  \n",
       "73677  START_ bạn nghĩ cái nào là vật dụng văn phòng ...         10         20  \n",
       "70879  START_ cô ấy nói rằng cô ấy nhìn thấy bức ảnh ...          6         18  \n",
       "77177  START_ tiếc thật kéo co là hạng mục có nhiều t...          6         14  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## counting length of english and hindi sentence\n",
    "data['kr_length'] = data['kr'].apply(lambda x: len(x.split(' ')))\n",
    "data['vn_length'] = data['vn'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba02335b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:31.307604Z",
     "iopub.status.busy": "2022-05-15T07:31:31.307382Z",
     "iopub.status.idle": "2022-05-15T07:31:31.333538Z",
     "shell.execute_reply": "2022-05-15T07:31:31.332871Z"
    },
    "papermill": {
     "duration": 0.05974,
     "end_time": "2022-05-15T07:31:31.335446",
     "exception": false,
     "start_time": "2022-05-15T07:31:31.275706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of Korean Sentence:  22\n",
      "Maximum length of Vietnam Sentence:  47\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of Korean Sentence: \", max(data['kr_length']))\n",
    "print(\"Maximum length of Vietnam Sentence: \",max(data['vn_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ade55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:31.401152Z",
     "iopub.status.busy": "2022-05-15T07:31:31.400944Z",
     "iopub.status.idle": "2022-05-15T07:31:31.864192Z",
     "shell.execute_reply": "2022-05-15T07:31:31.863459Z"
    },
    "papermill": {
     "duration": 0.49955,
     "end_time": "2022-05-15T07:31:31.866083",
     "exception": false,
     "start_time": "2022-05-15T07:31:31.366533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toral Korean words:  92864\n",
      "total Vietnam words:  8420\n"
     ]
    }
   ],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_kr_words=set()\n",
    "for kor in data['kr']:\n",
    "    for word in kor.split():\n",
    "        if word not in all_kr_words:\n",
    "            all_kr_words.add(word)\n",
    "\n",
    "all_vn_words=set()\n",
    "for viet in data['vn']:\n",
    "    for word in viet.split():\n",
    "        if word not in all_vn_words:\n",
    "            all_vn_words.add(word)\n",
    "            \n",
    "\n",
    "print(\"toral Korean words: \",len(all_kr_words))\n",
    "print('total Vietnam words: ',len(all_vn_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375894b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:31.930251Z",
     "iopub.status.busy": "2022-05-15T07:31:31.929676Z",
     "iopub.status.idle": "2022-05-15T07:31:31.944132Z",
     "shell.execute_reply": "2022-05-15T07:31:31.943361Z"
    },
    "papermill": {
     "duration": 0.048149,
     "end_time": "2022-05-15T07:31:31.945983",
     "exception": false,
     "start_time": "2022-05-15T07:31:31.897834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85633, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using only sentence with length less than 20\n",
    "mask1 = data['kr_length'] < 21\n",
    "mask2 = data['vn_length'] < 21\n",
    "data = data[mask1 & mask2]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344c7968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.010703Z",
     "iopub.status.busy": "2022-05-15T07:31:32.010489Z",
     "iopub.status.idle": "2022-05-15T07:31:32.036773Z",
     "shell.execute_reply": "2022-05-15T07:31:32.035649Z"
    },
    "papermill": {
     "duration": 0.060831,
     "end_time": "2022-05-15T07:31:32.038955",
     "exception": false,
     "start_time": "2022-05-15T07:31:31.978124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Vietnam Sentence  20\n",
      "maximum length of Korean Sentence  16\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Vietnam Sentence \",max(data['vn_length']))\n",
    "print(\"maximum length of Korean Sentence \",max(data['kr_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3141ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.104888Z",
     "iopub.status.busy": "2022-05-15T07:31:32.104385Z",
     "iopub.status.idle": "2022-05-15T07:31:32.162786Z",
     "shell.execute_reply": "2022-05-15T07:31:32.161945Z"
    },
    "papermill": {
     "duration": 0.093786,
     "end_time": "2022-05-15T07:31:32.165393",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.071607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92864, 8420)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_kr_words))\n",
    "target_words = sorted(list(all_vn_words))\n",
    "num_encoder_tokens = len(all_kr_words)\n",
    "num_decoder_tokens = len(all_vn_words)\n",
    "\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "077ae15c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.230969Z",
     "iopub.status.busy": "2022-05-15T07:31:32.230653Z",
     "iopub.status.idle": "2022-05-15T07:31:32.234022Z",
     "shell.execute_reply": "2022-05-15T07:31:32.233358Z"
    },
    "papermill": {
     "duration": 0.038113,
     "end_time": "2022-05-15T07:31:32.235655",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.197542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06f9e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.300447Z",
     "iopub.status.busy": "2022-05-15T07:31:32.300244Z",
     "iopub.status.idle": "2022-05-15T07:31:32.359478Z",
     "shell.execute_reply": "2022-05-15T07:31:32.358665Z"
    },
    "papermill": {
     "duration": 0.095455,
     "end_time": "2022-05-15T07:31:32.362776",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.267321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token for accelerating is:  50\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "print(\"Token for accelerating is: \",input_token_index['cfo로'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6adfc386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.429257Z",
     "iopub.status.busy": "2022-05-15T07:31:32.428952Z",
     "iopub.status.idle": "2022-05-15T07:31:32.455325Z",
     "shell.execute_reply": "2022-05-15T07:31:32.454486Z"
    },
    "papermill": {
     "duration": 0.061631,
     "end_time": "2022-05-15T07:31:32.456979",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.395348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character for toker 50 is:  cfo로\n"
     ]
    }
   ],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "print(\"Character for toker 50 is: \",reverse_input_char_index[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f531423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.526801Z",
     "iopub.status.busy": "2022-05-15T07:31:32.526580Z",
     "iopub.status.idle": "2022-05-15T07:31:32.548305Z",
     "shell.execute_reply": "2022-05-15T07:31:32.547192Z"
    },
    "papermill": {
     "duration": 0.057636,
     "end_time": "2022-05-15T07:31:32.550493",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.492857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training data:  68506\n",
      "Toral number of testing data:  17127\n"
     ]
    }
   ],
   "source": [
    "# splitting data\n",
    "X_, y_ = data['kr'], data['vn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2,random_state=42)\n",
    "print(\"Total number of training data: \",X_train.shape[0])\n",
    "print(\"Toral number of testing data: \",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef2b19f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:32.618763Z",
     "iopub.status.busy": "2022-05-15T07:31:32.618206Z",
     "iopub.status.idle": "2022-05-15T07:31:37.170092Z",
     "shell.execute_reply": "2022-05-15T07:31:37.169325Z"
    },
    "papermill": {
     "duration": 4.587855,
     "end_time": "2022-05-15T07:31:37.172080",
     "exception": false,
     "start_time": "2022-05-15T07:31:32.584225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 07:31:32.720668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:32.826127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:32.826936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:32.828226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-15 07:31:32.828525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:32.829216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:32.829850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:35.065406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:35.066315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:35.067016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-15 07:31:35.068638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    27859200    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2526300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8421)   2534721     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 34,362,621\n",
      "Trainable params: 34,362,621\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5631547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:37.241844Z",
     "iopub.status.busy": "2022-05-15T07:31:37.241633Z",
     "iopub.status.idle": "2022-05-15T07:31:37.253594Z",
     "shell.execute_reply": "2022-05-15T07:31:37.252945Z"
    },
    "papermill": {
     "duration": 0.048682,
     "end_time": "2022-05-15T07:31:37.255250",
     "exception": false,
     "start_time": "2022-05-15T07:31:37.206568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae5c55d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:37.324011Z",
     "iopub.status.busy": "2022-05-15T07:31:37.323488Z",
     "iopub.status.idle": "2022-05-15T07:31:37.332205Z",
     "shell.execute_reply": "2022-05-15T07:31:37.331503Z"
    },
    "papermill": {
     "duration": 0.044821,
     "end_time": "2022-05-15T07:31:37.333793",
     "exception": false,
     "start_time": "2022-05-15T07:31:37.288972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length_src = 20\n",
    "max_length_tar = 20 \n",
    "\n",
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfda2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:37.402719Z",
     "iopub.status.busy": "2022-05-15T07:31:37.402167Z",
     "iopub.status.idle": "2022-05-15T07:31:37.406021Z",
     "shell.execute_reply": "2022-05-15T07:31:37.405304Z"
    },
    "papermill": {
     "duration": 0.03984,
     "end_time": "2022-05-15T07:31:37.407652",
     "exception": false,
     "start_time": "2022-05-15T07:31:37.367812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ac4c1e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T07:31:37.478307Z",
     "iopub.status.busy": "2022-05-15T07:31:37.478098Z",
     "iopub.status.idle": "2022-05-15T10:18:49.792372Z",
     "shell.execute_reply": "2022-05-15T10:18:49.791702Z"
    },
    "papermill": {
     "duration": 10032.351829,
     "end_time": "2022-05-15T10:18:49.794125",
     "exception": false,
     "start_time": "2022-05-15T07:31:37.442296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 07:31:37.680303: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 07:31:44.307412: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535/535 [==============================] - 107s 185ms/step - loss: 3.4098 - accuracy: 0.1557 - val_loss: 2.9617 - val_accuracy: 0.2303\n",
      "Epoch 2/100\n",
      "535/535 [==============================] - 98s 182ms/step - loss: 2.7124 - accuracy: 0.2851 - val_loss: 2.5510 - val_accuracy: 0.3189\n",
      "Epoch 3/100\n",
      "535/535 [==============================] - 98s 184ms/step - loss: 2.3797 - accuracy: 0.3536 - val_loss: 2.3331 - val_accuracy: 0.3653\n",
      "Epoch 4/100\n",
      "535/535 [==============================] - 98s 184ms/step - loss: 2.1567 - accuracy: 0.3983 - val_loss: 2.2071 - val_accuracy: 0.3918\n",
      "Epoch 5/100\n",
      "535/535 [==============================] - 98s 184ms/step - loss: 1.9823 - accuracy: 0.4341 - val_loss: 2.1295 - val_accuracy: 0.4067\n",
      "Epoch 6/100\n",
      "535/535 [==============================] - 99s 184ms/step - loss: 1.8353 - accuracy: 0.4655 - val_loss: 2.0914 - val_accuracy: 0.4163\n",
      "Epoch 7/100\n",
      "535/535 [==============================] - 99s 186ms/step - loss: 1.7061 - accuracy: 0.4946 - val_loss: 2.0809 - val_accuracy: 0.4209\n",
      "Epoch 8/100\n",
      "535/535 [==============================] - 100s 186ms/step - loss: 1.5901 - accuracy: 0.5220 - val_loss: 2.0658 - val_accuracy: 0.4256\n",
      "Epoch 9/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 1.4844 - accuracy: 0.5480 - val_loss: 2.0785 - val_accuracy: 0.4243\n",
      "Epoch 10/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 1.3870 - accuracy: 0.5729 - val_loss: 2.1022 - val_accuracy: 0.4226\n",
      "Epoch 11/100\n",
      "535/535 [==============================] - 100s 188ms/step - loss: 1.2971 - accuracy: 0.5964 - val_loss: 2.1340 - val_accuracy: 0.4180\n",
      "Epoch 12/100\n",
      "535/535 [==============================] - 100s 188ms/step - loss: 1.2139 - accuracy: 0.6197 - val_loss: 2.1621 - val_accuracy: 0.4172\n",
      "Epoch 13/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 1.1353 - accuracy: 0.6421 - val_loss: 2.1973 - val_accuracy: 0.4169\n",
      "Epoch 14/100\n",
      "535/535 [==============================] - 100s 188ms/step - loss: 1.0639 - accuracy: 0.6620 - val_loss: 2.2371 - val_accuracy: 0.4156\n",
      "Epoch 15/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.9960 - accuracy: 0.6824 - val_loss: 2.2819 - val_accuracy: 0.4131\n",
      "Epoch 16/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.9335 - accuracy: 0.7010 - val_loss: 2.3132 - val_accuracy: 0.4102\n",
      "Epoch 17/100\n",
      "535/535 [==============================] - 101s 190ms/step - loss: 0.8748 - accuracy: 0.7197 - val_loss: 2.3627 - val_accuracy: 0.4087\n",
      "Epoch 18/100\n",
      "535/535 [==============================] - 99s 185ms/step - loss: 0.8199 - accuracy: 0.7365 - val_loss: 2.4048 - val_accuracy: 0.4047\n",
      "Epoch 19/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.7691 - accuracy: 0.7524 - val_loss: 2.4412 - val_accuracy: 0.4016\n",
      "Epoch 20/100\n",
      "535/535 [==============================] - 98s 184ms/step - loss: 0.7206 - accuracy: 0.7685 - val_loss: 2.4867 - val_accuracy: 0.4011\n",
      "Epoch 21/100\n",
      "535/535 [==============================] - 101s 188ms/step - loss: 0.6769 - accuracy: 0.7828 - val_loss: 2.5231 - val_accuracy: 0.4025\n",
      "Epoch 22/100\n",
      "535/535 [==============================] - 99s 185ms/step - loss: 0.6357 - accuracy: 0.7968 - val_loss: 2.5627 - val_accuracy: 0.3989\n",
      "Epoch 23/100\n",
      "535/535 [==============================] - 99s 185ms/step - loss: 0.5968 - accuracy: 0.8099 - val_loss: 2.6035 - val_accuracy: 0.3967\n",
      "Epoch 24/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.5609 - accuracy: 0.8224 - val_loss: 2.6394 - val_accuracy: 0.3944\n",
      "Epoch 25/100\n",
      "535/535 [==============================] - 99s 185ms/step - loss: 0.5277 - accuracy: 0.8331 - val_loss: 2.6795 - val_accuracy: 0.3906\n",
      "Epoch 26/100\n",
      "535/535 [==============================] - 100s 186ms/step - loss: 0.4959 - accuracy: 0.8445 - val_loss: 2.7028 - val_accuracy: 0.3944\n",
      "Epoch 27/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.4670 - accuracy: 0.8543 - val_loss: 2.7442 - val_accuracy: 0.3919\n",
      "Epoch 28/100\n",
      "535/535 [==============================] - 99s 186ms/step - loss: 0.4401 - accuracy: 0.8634 - val_loss: 2.7716 - val_accuracy: 0.3897\n",
      "Epoch 29/100\n",
      "535/535 [==============================] - 100s 186ms/step - loss: 0.4145 - accuracy: 0.8719 - val_loss: 2.7995 - val_accuracy: 0.3889\n",
      "Epoch 30/100\n",
      "535/535 [==============================] - 102s 192ms/step - loss: 0.3907 - accuracy: 0.8800 - val_loss: 2.8286 - val_accuracy: 0.3902\n",
      "Epoch 31/100\n",
      "535/535 [==============================] - 101s 188ms/step - loss: 0.3683 - accuracy: 0.8874 - val_loss: 2.8661 - val_accuracy: 0.3892\n",
      "Epoch 32/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.3487 - accuracy: 0.8940 - val_loss: 2.8999 - val_accuracy: 0.3872\n",
      "Epoch 33/100\n",
      "535/535 [==============================] - 105s 196ms/step - loss: 0.3292 - accuracy: 0.9006 - val_loss: 2.9213 - val_accuracy: 0.3891\n",
      "Epoch 34/100\n",
      "535/535 [==============================] - 101s 188ms/step - loss: 0.3115 - accuracy: 0.9064 - val_loss: 2.9375 - val_accuracy: 0.3909\n",
      "Epoch 35/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.2950 - accuracy: 0.9120 - val_loss: 2.9647 - val_accuracy: 0.3902\n",
      "Epoch 36/100\n",
      "535/535 [==============================] - 101s 188ms/step - loss: 0.2802 - accuracy: 0.9172 - val_loss: 2.9992 - val_accuracy: 0.3890\n",
      "Epoch 37/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.2660 - accuracy: 0.9217 - val_loss: 3.0154 - val_accuracy: 0.3891\n",
      "Epoch 38/100\n",
      "535/535 [==============================] - 100s 188ms/step - loss: 0.2526 - accuracy: 0.9260 - val_loss: 3.0395 - val_accuracy: 0.3887\n",
      "Epoch 39/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.2406 - accuracy: 0.9298 - val_loss: 3.0561 - val_accuracy: 0.3879\n",
      "Epoch 40/100\n",
      "535/535 [==============================] - 100s 187ms/step - loss: 0.2282 - accuracy: 0.9344 - val_loss: 3.0709 - val_accuracy: 0.3866\n",
      "Epoch 41/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.2177 - accuracy: 0.9375 - val_loss: 3.0849 - val_accuracy: 0.3878\n",
      "Epoch 42/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.2078 - accuracy: 0.9405 - val_loss: 3.1055 - val_accuracy: 0.3861\n",
      "Epoch 43/100\n",
      "535/535 [==============================] - 100s 188ms/step - loss: 0.1986 - accuracy: 0.9436 - val_loss: 3.1235 - val_accuracy: 0.3848\n",
      "Epoch 44/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.1897 - accuracy: 0.9466 - val_loss: 3.1300 - val_accuracy: 0.3865\n",
      "Epoch 45/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.1821 - accuracy: 0.9488 - val_loss: 3.1445 - val_accuracy: 0.3865\n",
      "Epoch 46/100\n",
      "535/535 [==============================] - 99s 185ms/step - loss: 0.1742 - accuracy: 0.9514 - val_loss: 3.1644 - val_accuracy: 0.3866\n",
      "Epoch 47/100\n",
      "535/535 [==============================] - 102s 191ms/step - loss: 0.1671 - accuracy: 0.9536 - val_loss: 3.1798 - val_accuracy: 0.3881\n",
      "Epoch 48/100\n",
      "535/535 [==============================] - 102s 192ms/step - loss: 0.1606 - accuracy: 0.9554 - val_loss: 3.1850 - val_accuracy: 0.3867\n",
      "Epoch 49/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.1548 - accuracy: 0.9574 - val_loss: 3.1998 - val_accuracy: 0.3867\n",
      "Epoch 50/100\n",
      "535/535 [==============================] - 102s 191ms/step - loss: 0.1486 - accuracy: 0.9590 - val_loss: 3.2077 - val_accuracy: 0.3861\n",
      "Epoch 51/100\n",
      "535/535 [==============================] - 102s 192ms/step - loss: 0.1432 - accuracy: 0.9608 - val_loss: 3.2242 - val_accuracy: 0.3856\n",
      "Epoch 52/100\n",
      "535/535 [==============================] - 101s 189ms/step - loss: 0.1378 - accuracy: 0.9626 - val_loss: 3.2441 - val_accuracy: 0.3841\n",
      "Epoch 53/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.1328 - accuracy: 0.9640 - val_loss: 3.2534 - val_accuracy: 0.3845\n",
      "Epoch 54/100\n",
      "535/535 [==============================] - 104s 194ms/step - loss: 0.1286 - accuracy: 0.9651 - val_loss: 3.2591 - val_accuracy: 0.3848\n",
      "Epoch 55/100\n",
      "535/535 [==============================] - 103s 192ms/step - loss: 0.1241 - accuracy: 0.9665 - val_loss: 3.2791 - val_accuracy: 0.3830\n",
      "Epoch 56/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.1197 - accuracy: 0.9678 - val_loss: 3.2852 - val_accuracy: 0.3848\n",
      "Epoch 57/100\n",
      "535/535 [==============================] - 102s 191ms/step - loss: 0.1158 - accuracy: 0.9689 - val_loss: 3.3049 - val_accuracy: 0.3834\n",
      "Epoch 58/100\n",
      "535/535 [==============================] - 102s 191ms/step - loss: 0.1123 - accuracy: 0.9698 - val_loss: 3.3077 - val_accuracy: 0.3825\n",
      "Epoch 59/100\n",
      "535/535 [==============================] - 98s 182ms/step - loss: 0.1088 - accuracy: 0.9708 - val_loss: 3.3317 - val_accuracy: 0.3814\n",
      "Epoch 60/100\n",
      "535/535 [==============================] - 102s 191ms/step - loss: 0.1052 - accuracy: 0.9718 - val_loss: 3.3286 - val_accuracy: 0.3837\n",
      "Epoch 61/100\n",
      "535/535 [==============================] - 103s 192ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 3.3390 - val_accuracy: 0.3831\n",
      "Epoch 62/100\n",
      "535/535 [==============================] - 98s 182ms/step - loss: 0.0990 - accuracy: 0.9734 - val_loss: 3.3473 - val_accuracy: 0.3829\n",
      "Epoch 63/100\n",
      "535/535 [==============================] - 102s 192ms/step - loss: 0.0964 - accuracy: 0.9741 - val_loss: 3.3519 - val_accuracy: 0.3850\n",
      "Epoch 64/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0934 - accuracy: 0.9750 - val_loss: 3.3732 - val_accuracy: 0.3864\n",
      "Epoch 65/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 3.3779 - val_accuracy: 0.3840\n",
      "Epoch 66/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0885 - accuracy: 0.9763 - val_loss: 3.3823 - val_accuracy: 0.3838\n",
      "Epoch 67/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0861 - accuracy: 0.9768 - val_loss: 3.3915 - val_accuracy: 0.3850\n",
      "Epoch 68/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0838 - accuracy: 0.9775 - val_loss: 3.4073 - val_accuracy: 0.3833\n",
      "Epoch 69/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0813 - accuracy: 0.9783 - val_loss: 3.4136 - val_accuracy: 0.3861\n",
      "Epoch 70/100\n",
      "535/535 [==============================] - 104s 194ms/step - loss: 0.0796 - accuracy: 0.9784 - val_loss: 3.4268 - val_accuracy: 0.3835\n",
      "Epoch 71/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0779 - accuracy: 0.9789 - val_loss: 3.4394 - val_accuracy: 0.3838\n",
      "Epoch 72/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0754 - accuracy: 0.9796 - val_loss: 3.4509 - val_accuracy: 0.3826\n",
      "Epoch 73/100\n",
      "535/535 [==============================] - 104s 194ms/step - loss: 0.0741 - accuracy: 0.9800 - val_loss: 3.4603 - val_accuracy: 0.3828\n",
      "Epoch 74/100\n",
      "535/535 [==============================] - 97s 181ms/step - loss: 0.0723 - accuracy: 0.9804 - val_loss: 3.4691 - val_accuracy: 0.3840\n",
      "Epoch 75/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0707 - accuracy: 0.9809 - val_loss: 3.4781 - val_accuracy: 0.3826\n",
      "Epoch 76/100\n",
      "535/535 [==============================] - 104s 195ms/step - loss: 0.0693 - accuracy: 0.9811 - val_loss: 3.4886 - val_accuracy: 0.3820\n",
      "Epoch 77/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0675 - accuracy: 0.9817 - val_loss: 3.4956 - val_accuracy: 0.3824\n",
      "Epoch 78/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 3.4947 - val_accuracy: 0.3830\n",
      "Epoch 79/100\n",
      "535/535 [==============================] - 104s 195ms/step - loss: 0.0650 - accuracy: 0.9821 - val_loss: 3.5189 - val_accuracy: 0.3805\n",
      "Epoch 80/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 3.5185 - val_accuracy: 0.3823\n",
      "Epoch 81/100\n",
      "535/535 [==============================] - 104s 194ms/step - loss: 0.0626 - accuracy: 0.9827 - val_loss: 3.5328 - val_accuracy: 0.3802\n",
      "Epoch 82/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 3.5361 - val_accuracy: 0.3823\n",
      "Epoch 83/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0602 - accuracy: 0.9834 - val_loss: 3.5465 - val_accuracy: 0.3824\n",
      "Epoch 84/100\n",
      "535/535 [==============================] - 104s 195ms/step - loss: 0.0594 - accuracy: 0.9835 - val_loss: 3.5513 - val_accuracy: 0.3811\n",
      "Epoch 85/100\n",
      "535/535 [==============================] - 97s 181ms/step - loss: 0.0585 - accuracy: 0.9837 - val_loss: 3.5630 - val_accuracy: 0.3823\n",
      "Epoch 86/100\n",
      "535/535 [==============================] - 97s 181ms/step - loss: 0.0573 - accuracy: 0.9841 - val_loss: 3.5695 - val_accuracy: 0.3820\n",
      "Epoch 87/100\n",
      "535/535 [==============================] - 105s 195ms/step - loss: 0.0562 - accuracy: 0.9843 - val_loss: 3.5829 - val_accuracy: 0.3819\n",
      "Epoch 88/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0553 - accuracy: 0.9846 - val_loss: 3.5788 - val_accuracy: 0.3830\n",
      "Epoch 89/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0547 - accuracy: 0.9847 - val_loss: 3.5871 - val_accuracy: 0.3828\n",
      "Epoch 90/100\n",
      "535/535 [==============================] - 106s 198ms/step - loss: 0.0540 - accuracy: 0.9848 - val_loss: 3.6005 - val_accuracy: 0.3801\n",
      "Epoch 91/100\n",
      "535/535 [==============================] - 97s 181ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 3.6085 - val_accuracy: 0.3817\n",
      "Epoch 92/100\n",
      "535/535 [==============================] - 103s 193ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 3.6277 - val_accuracy: 0.3814\n",
      "Epoch 93/100\n",
      "535/535 [==============================] - 99s 186ms/step - loss: 0.0515 - accuracy: 0.9854 - val_loss: 3.6282 - val_accuracy: 0.3807\n",
      "Epoch 94/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0508 - accuracy: 0.9856 - val_loss: 3.6403 - val_accuracy: 0.3798\n",
      "Epoch 95/100\n",
      "535/535 [==============================] - 106s 198ms/step - loss: 0.0501 - accuracy: 0.9858 - val_loss: 3.6382 - val_accuracy: 0.3807\n",
      "Epoch 96/100\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 3.6430 - val_accuracy: 0.3804\n",
      "Epoch 97/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 3.6475 - val_accuracy: 0.3798\n",
      "Epoch 98/100\n",
      "535/535 [==============================] - 106s 199ms/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 3.6615 - val_accuracy: 0.3796\n",
      "Epoch 99/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0478 - accuracy: 0.9864 - val_loss: 3.6549 - val_accuracy: 0.3801\n",
      "Epoch 100/100\n",
      "535/535 [==============================] - 98s 183ms/step - loss: 0.0469 - accuracy: 0.9868 - val_loss: 3.6731 - val_accuracy: 0.3791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f090c8cc390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49258784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:19:24.247872Z",
     "iopub.status.busy": "2022-05-15T10:19:24.247580Z",
     "iopub.status.idle": "2022-05-15T10:19:24.773029Z",
     "shell.execute_reply": "2022-05-15T10:19:24.772301Z"
    },
    "papermill": {
     "duration": 18.209946,
     "end_time": "2022-05-15T10:19:24.775079",
     "exception": false,
     "start_time": "2022-05-15T10:19:06.565133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2258e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:19:59.336281Z",
     "iopub.status.busy": "2022-05-15T10:19:59.336006Z",
     "iopub.status.idle": "2022-05-15T10:20:00.001711Z",
     "shell.execute_reply": "2022-05-15T10:20:00.000995Z"
    },
    "papermill": {
     "duration": 18.040719,
     "end_time": "2022-05-15T10:20:00.003755",
     "exception": false,
     "start_time": "2022-05-15T10:19:41.963036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "927b396f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:20:34.405474Z",
     "iopub.status.busy": "2022-05-15T10:20:34.405210Z",
     "iopub.status.idle": "2022-05-15T10:20:34.409039Z",
     "shell.execute_reply": "2022-05-15T10:20:34.408265Z"
    },
    "papermill": {
     "duration": 17.312059,
     "end_time": "2022-05-15T10:20:34.411105",
     "exception": false,
     "start_time": "2022-05-15T10:20:17.099046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e8f83e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:21:09.007486Z",
     "iopub.status.busy": "2022-05-15T10:21:09.007165Z",
     "iopub.status.idle": "2022-05-15T10:21:11.487126Z",
     "shell.execute_reply": "2022-05-15T10:21:11.486359Z"
    },
    "papermill": {
     "duration": 19.959645,
     "end_time": "2022-05-15T10:21:11.488906",
     "exception": false,
     "start_time": "2022-05-15T10:20:51.529261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Korean sentence: 그는 버디 퍼팅을 했지만 컵을 벗어났어요\n",
      "Actual Vietnam Translation:  anh ấy đã đánh birdie putting nhưng anh ấy đã rời khỏi cốc \n",
      "Predicted Vietnam Translation:  anh ấy đã đánh hơn anh ấy đã nói ngoài vào mùa \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Korean sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Vietnam Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Vietnam Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d906c862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:21:46.387547Z",
     "iopub.status.busy": "2022-05-15T10:21:46.387294Z",
     "iopub.status.idle": "2022-05-15T10:21:46.891962Z",
     "shell.execute_reply": "2022-05-15T10:21:46.891232Z"
    },
    "papermill": {
     "duration": 17.518395,
     "end_time": "2022-05-15T10:21:46.894065",
     "exception": false,
     "start_time": "2022-05-15T10:21:29.375670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Korean sentence: 항상 좋은 인연으로 기억되길 바래요\n",
      "Actual Vietnam Translation:  tôi hy vọng bạn sẽ luôn nhớ đến mối nhân duyên tốt đẹp \n",
      "Predicted Vietnam Translation:  tôi hy vọng bạn sẽ luôn nhớ đến mối nhân duyên\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Korean sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Vietnam Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Vietnam Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5cbe973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:22:21.730879Z",
     "iopub.status.busy": "2022-05-15T10:22:21.730605Z",
     "iopub.status.idle": "2022-05-15T10:22:22.304669Z",
     "shell.execute_reply": "2022-05-15T10:22:22.302669Z"
    },
    "papermill": {
     "duration": 17.628189,
     "end_time": "2022-05-15T10:22:22.306724",
     "exception": false,
     "start_time": "2022-05-15T10:22:04.678535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Korean sentence: 바로 공항에 전화해서 비행기 번호와 시간을 말하고 물어봐\n",
      "Actual Vietnam Translation:  chính là sân bay gọi điện đến số hiệu máy bay và thời gian nói và hỏi đi \n",
      "Predicted Vietnam Translation:  chính là sân bay gọi điện đến số thời gian và nói ch\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Korean sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Vietnam Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Vietnam Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4e4cb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T10:22:56.892134Z",
     "iopub.status.busy": "2022-05-15T10:22:56.891891Z",
     "iopub.status.idle": "2022-05-15T10:22:57.347937Z",
     "shell.execute_reply": "2022-05-15T10:22:57.347259Z"
    },
    "papermill": {
     "duration": 17.380109,
     "end_time": "2022-05-15T10:22:57.349749",
     "exception": false,
     "start_time": "2022-05-15T10:22:39.969640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Korean sentence: 최종 목표는 실리콘밸리로 진출하고 세계 시장에 진입하는 것입니다\n",
      "Actual Vietnam Translation:  mục tiêu cuối cùng là tiến vào thung lũng silicon và tiến vào thị trường thế giới \n",
      "Predicted Vietnam Translation:  mục tiêu cuối cùng là tiến vào thung lũng silico\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Korean sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Vietnam Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Vietnam Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259cd76",
   "metadata": {
    "papermill": {
     "duration": 17.105232,
     "end_time": "2022-05-15T10:23:32.282964",
     "exception": false,
     "start_time": "2022-05-15T10:23:15.177732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a2efe",
   "metadata": {
    "papermill": {
     "duration": 17.259344,
     "end_time": "2022-05-15T10:24:06.901106",
     "exception": false,
     "start_time": "2022-05-15T10:23:49.641762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10395.075364,
   "end_time": "2022-05-15T10:24:27.630296",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-15T07:31:12.554932",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
